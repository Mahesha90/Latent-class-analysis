---
title: "Program Director Interviews"
output:
  html_document:
    df_print: paged
  pdf_document: default
---

Here, we present an analysis of the interviews with program directors, step by step.

load libraries
```{r}
library(GPArotation)
library(lattice)
library(nFactors)
library(psych)
library(dplyr)
library(poLCA)
library(irr)

```


read data for LCA

```{r}
lca.data <- read.table("./Binary_AllCodes_12.txt", header = TRUE)
tocluster <- lca.data[,c(-1)]
```

```{r}
wss <- (nrow(tocluster)-1)*sum(apply(tocluster,2,var))
for (i in 2:12) wss[i] <- sum(kmeans(tocluster, centers=i)$withinss)
plot(1:12, wss, type="b", xlab="Number of Clusters",
  ylab="Within groups sum of squares")
```


```{r}
lca11<- poLCA(cbind(SocietalIssue, StudentChoice, PoliticalProblem,	NotaHugeLoss,	NotMuchImpact,	Finishdegree,	GetPromotedinCareer,	LowCompletion,	LowProbabilityinJob,	WasteofInvestments,	StudenttookSomeonesplace,	N_PopularS,	NInterest,	OTransfer,	WSpeciality,	E_Workload,	FamilyI,	FinancialI,	HealthP,	Psyco_Social,	DifficulutCourse,	LearningD,	Employment,	Thesis,	Perfectionism,	Checkwithteachers,	Counseling,	ICourses,	Inform,	Tracking,	SupervisorC,	Talk,	SandCourses,	ImroveStudy_SelfM,	CurriculumDevelopmnet,	GroupDiscussions,	CantfigureSP,	DifficultConvince,	DifficultCont,	LecturersLI,	NPtakingActions,	TooLate,	WorkHours,	TMIssues,	OwnData,	UseSIS,	PositiveImp,	LiketoseeStudentD,	NagativeImp)~1, lca.data, nclass=11, nrep = 100, na.rm=FALSE, graphs=T)
```
```{r}
lca11$predclass

#the numbers below indicate the clusters of participants. For example participants Philosophy 4, Romance 4 and Pharmacy 3, have all been placed in the same cluster.
```


#codes clustering
```{r}
codes.data <- t(lca.data)

codes.data <-as.data.frame(codes.data[-1,])
colnames(codes.data)<- c("SE1","SE3","Philosophy2","Philosophy3","Philosophy4","Counselling1","Counselling2","Counselling3","Romance2","Romance3","Romance4","Pharmacy2","Pharmacy3")
```

```{r}
wss <- (nrow(codes.data)-1)*sum(apply(codes.data,2,var))
for (i in 2:37) wss[i] <- sum(kmeans(codes.data, centers=i)$withinss)
plot(1:37, wss, type="b", xlab="Number of Clusters",
  ylab="Within groups sum of squares")
```

Try the LCA for the codes clustering this time

```{r}
lca11codes<- poLCA(cbind(SE1, SE3, Philosophy2, Philosophy3, Philosophy4, Counselling1, Counselling2, Counselling3, Romance2, Romance3, Romance4, Pharmacy2, Pharmacy3)~1, codes.data, nclass=11, nrep = 100, na.rm=FALSE, graphs=T)
```

```{r}
lca11codes$predclass

#the numbers below indicate the high-order clusters of codes. The idea here is to examine whether these high-order clusters have underlying semantics.
```


```{r}
codes.data["code.clusters"] <- lca11codes$predclass
```

END



-------------mahesha-----------------------------------------
below you can transfer the code from test.R. I've tried to adapt some
# Factor Analysis for All codes

This has done for both "All codes" and "DropoutReasons"
question: what do you mean "for both"? 
Answer

From that I meant-All codes=all the codes derived from the analysis (e.g., dropouts is a major concern, dropout reasons, strategies, issues)
Dropout reasons =the codes derived from (dropouts as a major concern and dropout reasons ). 

But I change the codebook a little, and there's no to separate versions anymore. Sorry for the confusion :(


```{r}
#data <- read.delim(file.choose(),header = TRUE)
dataFA <-read.delim("./Binary_Factor.txt", header = TRUE)
#View(data)
```

```{r}
View(dataFA)
```


#CorrelationMatrix
question: these correlations do not take into account statistical significance, right? Yes
```{r}
raqMatrix <- cor(dataFA[2:50])

head(round(raqMatrix, 2))
```

I looked for heavily weighted (greater than 0.9) variables in thecorrelation matrix,. Since there's no heavily weighted variables PCA was calculated.

question: Not sure whats going on here? If you un-comment and re-run, it gives an error

Answer: chances are you have another package attached that also has a select function and R thinks you are calling that. Thus; I changed it as dplyr::select.  Now it should be work
```{r}
dataFA <- dplyr::select(dataFA, Student_Choice,	Political_Problem,	No_negative_consequences,	FinishingDegreeisgood,	Getpromotedincareer,	LowCompletionRate,	University_Responsibility,	Less_Jobs,	Waste_of_Investments,	Missused_Opportunities,	University_Rankings,	Less_Popular_Specialisations,	Boring_study_path,	Opportunity_to_Transfer,	Wrong_Speciality,	Extreme_Workload,	Family_issues,	Financial_Issues,	Health_Issues,	Psychological_social_Issues,	Hard_Curricular,	Learning_Difficulties,	Less_Support_from_Uni,	Employment,	Thesis,	Student_Supervisor_Relationship,	Perfectionism,	Track_Student_Behaviour,	Counseling,	Academic_support_programs,	Inform_Relevant_People,	Track_Dropouts,	Supervisor_Communication,	Talk_to_Students,	Seminars_and_Courses,	Stuy_and_SelfManagement,	Curriculum_Development,	Group_Discussions,	To_check_courseregistration,	Check_study_results,	Tax_office_data,	Industry_perspectives,	Qualitative_Data,	Previous_Studies,	Admission_Choice,	Reasonfor_Academic_Leaves,	Numberof_studentdropouts,	Admission_Score,	Extracurricular_courses,	credits_Nextsem_Previoussem,	LowGrades_FailedCourses,	Nextsem_Payments,	International_National_Clusters)
```


PCA to identify the number of factors
```{r}
dataFA.pca <- prcomp(dataFA)
summary(dataFA.pca)
plot(dataFA.pca)
```

Scree plot to find the number of factors
```{r}
ev <- eigen(cor(dataFA)) # get eigenvalues
ap <- parallel(subject=nrow(dataFA),var=ncol(dataFA),
               rep=100,cent=.05)
nS <- nScree(x=ev$values, aparallel=ap$eigen$qevpea)
plotnScree(nS)
```


I used Psych packageâ€™s fa.parallel function to execute the parallel analysis. The main goal of the parallel analysis is also to find out the number of factors.

```{r warning=FALSE}
parallel<-fa.parallel(dataFA, fm='minres', fa='fa')
```


Parallel analysis suggests that the number of factors =  3  and the number of components =  NA. Above 3 factors can describe as follows;

Factor 01: Political and Financial Issues
Factor 02: Institutional Issues
Factor 03: SOcietal Issues


Even though parallel analysis suggested to have 3 factors, based on the PCA data, I decided to run 4 factors.

library(nFactors)
```{r warning=FALSE}
fourFA <- fa(dataFA,nfactors = 4,rotate = "oblimin",fm="minres")
print(fourFA)
print(fourFA$loadings,cutoff = 0.3, sort=TRUE)
```

Based on the above factor loading, factors can describe as follows;
Factor 01: Societal Factors
Factor 02: INstitutional Support
Factor 03: Learning Difficulties
Factor 04: Disposition (Attitude towards the studies)


#-------------Latent Class Analysis------------------

```{r}
library(scatterplot3d)
library(MASS)
library(poLCA)
library(xlsx)
library("reshape2")
library("plyr")
library("dplyr")
library("poLCA")
library("ggplot2")
library("ggparallel")
library("igraph")
library("tidyr")
library("knitr")
```

Here as you mentioned I considered participant statement as the unit of analysis
```{r}
lca.data <-read.delim("./BinaryNew.txt",header = TRUE)
```

```{r}
lca11<- poLCA(cbind(SE1,	SE3,	Philosophy2,	Philosophy3,	Counselling1,	Counselling2,	Counselling3,	Romance2,	Romance3,	Romance4,	Pharmacy2,	Pharmacy3)~1, lca.data, nclass=11, nrep = 100, na.rm=FALSE, graphs=T)

```

```{r}
lca11$predclass

```

Here I tried to give a name for the classes based on the underlying semantics

Class 01: {Disposition(Attitude towards study)}

Opportunity_to_Transfer, credits_Nextsem_Previoussem, Nextsem_Payments


Class 02: {Personal and financial Reasons}

Student_Choice, Employment


Class 03: {Institutional support}

Missused_Opportunities, University_Rankings, Extreme_Workload, Psychological_social_Issues, Less_Support_from_Uni, Track_Dropouts, Supervisor_Communication, To_check_courseregistration, Check_study_results, Admission_Score


Class 04: {Student behaviour}

Less_Popular_Specialisations, Health_Issues, Track_Student_Behaviour, Academic_support_programs, Previous_Studies, Numberof_studentdropouts, Extracurricular_courses


CLass 05: {Student-University Interaction/Student Satisfaction}

Talk_to_Students, Curriculum_Development


Class 06: {Academic Outcomes}

Learning_Difficulties, Reasonfor_Academic_Leaves, LowGrades_FailedCourses


Class 07: {Stress}

Financial_Issues, Thesis, Student_Supervisor_Relationship, Stuy_and_SelfManagement


Class 08: {Political Concerns}

Political_Problem, No_negative_consequences, FinishingDegreeisgood, Getpromotedincareer, Less_Jobs, Waste_of_Investments, Boring_study_path, Family_issues, Perfectionism, Tax_office_data, Industry_perspectives, Qualitative_Data, International_National_Clusters


Class 09: {Mental support}

University_Responsibility, Counseling, Group_Discussions


Class 10: {Wrong studiy choices}

LowCompletionRate, Wrong_Speciality, Inform_Relevant_People, Admission_Choice


CLass 11: {Curriculum Concerns}

Hard_Curricular, Seminars_and_Courses



Select variable and define function for all codes
```{r}
mylcadata <- lca.data %>% dplyr::select(SE1,	SE3,	Philosophy2,	Philosophy3,	Counselling1,	Counselling2,	Counselling3,	Romance2,	Romance3,	Romance4,	Pharmacy2,	Pharmacy3)

f<-with(mylcadata, cbind(SE1,	SE3,	Philosophy2,	Philosophy3,	Counselling1,	Counselling2,	Counselling3,	Romance2,	Romance3,	Romance4,	Pharmacy2,	Pharmacy3)~1)
```

models with different number of groups

```{r}
set.seed(01012)
lc1<-poLCA(f, data=mylcadata, nclass=1, na.rm = FALSE, nrep=30, maxiter=3000) #Loglinear independence model.
lc2<-poLCA(f, data=mylcadata, nclass=2, na.rm = FALSE, nrep=30, maxiter=3000)
lc3<-poLCA(f, data=mylcadata, nclass=3, na.rm = FALSE, nrep=30, maxiter=3000)
lc4<-poLCA(f, data=mylcadata, nclass=4, na.rm = FALSE, nrep=30, maxiter=3000) 
lc5<-poLCA(f, data=mylcadata, nclass=5, na.rm = FALSE, nrep=30, maxiter=3000)
lc6<-poLCA(f, data=mylcadata, nclass=6, na.rm = FALSE, nrep=30, maxiter=3000)
lc7<-poLCA(f, data=mylcadata, nclass=7, na.rm = FALSE, nrep=30, maxiter=3000)
lc8<-poLCA(f, data=mylcadata, nclass=8, na.rm = FALSE, nrep=30, maxiter=3000)
lc9<-poLCA(f, data=mylcadata, nclass=9, na.rm = FALSE, nrep=30, maxiter=3000)
lc10<-poLCA(f, data=mylcadata, nclass=10, na.rm = FALSE, nrep=30, maxiter=3000)
lc11<-poLCA(f, data=mylcadata, nclass=11, na.rm = FALSE, nrep=30, maxiter=3000)
```

generate dataframe with fit-values

```{r}
results <- data.frame(Modell=c("Modell 1"),
                      log_likelihood=lc1$llik,
                      df = lc1$resid.df,
                      BIC=lc1$bic,
                      ABIC=  (-2*lc1$llik) + ((log((lc1$N + 2)/24)) * lc1$npar),
                      CAIC = (-2*lc1$llik) + lc1$npar * (1 + log(lc1$N)), 
                      likelihood_ratio=lc1$Gsq)
results$Modell<-as.integer(results$Modell)
results[1,1]<-c("Modell 1")
results[2,1]<-c("Modell 2")
results[3,1]<-c("Modell 3")
results[4,1]<-c("Modell 4")
results[5,1]<-c("Modell 5")
results[6,1]<-c("Modell 6")
results[7,1]<-c("Modell 7")
results[8,1]<-c("Modell 8")
results[9,1]<-c("Modell 9")
results[10,1]<-c("Modell 10")
results[11,1]<-c("Modell 11")

results[2,2]<-lc2$llik
results[3,2]<-lc3$llik
results[4,2]<-lc4$llik
results[5,2]<-lc5$llik
results[6,2]<-lc6$llik
results[7,2]<-lc7$llik
results[8,2]<-lc8$llik
results[9,2]<-lc9$llik
results[10,2]<-lc10$llik
results[11,2]<-lc11$llik


results[2,3]<-lc2$resid.df
results[3,3]<-lc3$resid.df
results[4,3]<-lc4$resid.df
results[5,3]<-lc5$resid.df
results[6,3]<-lc6$resid.df
results[7,3]<-lc7$resid.df
results[8,3]<-lc8$resid.df
results[9,3]<-lc9$resid.df
results[10,3]<-lc10$resid.df
results[11,3]<-lc11$resid.df

results[2,4]<-lc2$bic
results[3,4]<-lc3$bic
results[4,4]<-lc4$bic
results[5,4]<-lc5$bic
results[6,4]<-lc6$bic
results[7,4]<-lc7$bic
results[8,4]<-lc8$bic
results[9,4]<-lc9$bic
results[10,4]<-lc10$bic
results[11,4]<-lc11$bic

results[2,5]<-(-2*lc2$llik) + ((log((lc2$N + 2)/24)) * lc2$npar) #abic
results[3,5]<-(-2*lc3$llik) + ((log((lc3$N + 2)/24)) * lc3$npar)
results[4,5]<-(-2*lc4$llik) + ((log((lc4$N + 2)/24)) * lc4$npar)
results[5,5]<-(-2*lc5$llik) + ((log((lc5$N + 2)/24)) * lc5$npar)
results[6,5]<-(-2*lc6$llik) + ((log((lc6$N + 2)/24)) * lc6$npar)
results[7,5]<-(-2*lc7$llik) + ((log((lc7$N + 2)/24)) * lc7$npar)
results[8,5]<-(-2*lc8$llik) + ((log((lc8$N + 2)/24)) * lc8$npar)
results[9,5]<-(-2*lc9$llik) + ((log((lc9$N + 2)/24)) * lc9$npar)
results[10,5]<-(-2*lc10$llik) + ((log((lc10$N + 2)/24)) * lc10$npar)
results[11,5]<-(-2*lc11$llik) + ((log((lc11$N + 2)/24)) * lc11$npar)

results[2,6]<- (-2*lc2$llik) + lc2$npar * (1 + log(lc2$N)) #caic
results[3,6]<- (-2*lc3$llik) + lc3$npar * (1 + log(lc3$N))
results[4,6]<- (-2*lc4$llik) + lc4$npar * (1 + log(lc4$N))
results[5,6]<- (-2*lc5$llik) + lc5$npar * (1 + log(lc5$N))
results[6,6]<- (-2*lc6$llik) + lc6$npar * (1 + log(lc6$N))
results[7,6]<- (-2*lc7$llik) + lc7$npar * (1 + log(lc7$N))
results[8,6]<- (-2*lc8$llik) + lc8$npar * (1 + log(lc8$N))
results[9,6]<- (-2*lc9$llik) + lc9$npar * (1 + log(lc9$N))
results[10,6]<- (-2*lc10$llik) + lc10$npar * (1 + log(lc10$N))
results[11,6]<- (-2*lc11$llik) + lc11$npar * (1 + log(lc11$N))

results[2,7]<-lc2$Gsq
results[3,7]<-lc3$Gsq
results[4,7]<-lc4$Gsq
results[5,7]<-lc5$Gsq
results[6,7]<-lc6$Gsq
results[7,7]<-lc7$Gsq
results[8,7]<-lc8$Gsq
results[9,7]<-lc9$Gsq
results[10,7]<-lc10$Gsq
results[11,7]<-lc11$Gsq

results
```
Calculate Enthropy
```{r}
entropy<-function (p) sum(-p*log(p))

results$R2_entropy
results[1,8]<-c("-")

error_prior<-entropy(lc2$P) # class proportions model 2
error_post<-mean(apply(lc2$posterior,1, entropy),na.rm = TRUE)
results[2,8]<-round(((error_prior-error_post) / error_prior),3)

error_prior<-entropy(lc3$P) # class proportions model 3
error_post<-mean(apply(lc3$posterior,1, entropy),na.rm = TRUE)
results[3,8]<-round(((error_prior-error_post) / error_prior),3)

error_prior<-entropy(lc4$P) # class proportions model 4
error_post<-mean(apply(lc4$posterior,1, entropy),na.rm = TRUE)
results[4,8]<-round(((error_prior-error_post) / error_prior),3)

error_prior<-entropy(lc5$P) # class proportions model 5
error_post<-mean(apply(lc5$posterior,1, entropy),na.rm = TRUE)
results[5,8]<-round(((error_prior-error_post) / error_prior),3)

error_prior<-entropy(lc6$P) # class proportions model 6
error_post<-mean(apply(lc6$posterior,1, entropy),na.rm = TRUE)
results[6,8]<-round(((error_prior-error_post) / error_prior),3)

error_prior<-entropy(lc7$P) # class proportions model 7
error_post<-mean(apply(lc7$posterior,1, entropy),na.rm = TRUE)
results[7,8]<-round(((error_prior-error_post) / error_prior),3)

error_prior<-entropy(lc8$P) # class proportions model8
error_post<-mean(apply(lc8$posterior,1, entropy),na.rm = TRUE)
results[8,8]<-round(((error_prior-error_post) / error_prior),3)

error_prior<-entropy(lc9$P) # class proportions model 9
error_post<-mean(apply(lc9$posterior,1, entropy),na.rm = TRUE)
results[9,8]<-round(((error_prior-error_post) / error_prior),3)

error_prior<-entropy(lc10$P) # class proportions model 10
error_post<-mean(apply(lc10$posterior,1, entropy),na.rm = TRUE)
results[10,8]<-round(((error_prior-error_post) / error_prior),3)

error_prior<-entropy(lc11$P) # class proportions model 11
error_post<-mean(apply(lc11$posterior,1, entropy),na.rm = TRUE)
results[11,8]<-round(((error_prior-error_post) / error_prior),3)
```

combining results to a dataframe
```{r}
colnames(results)<-c("Model","log-likelihood","resid. df","BIC","aBIC","cAIC","likelihood-ratio","Entropy")
lca_results<-results

library(ztable)
ztable::ztable(lca_results)
```


#-------------------Cluster Analysis-----------------

```{r}
library(tidyverse)  # data manipulation
library(cluster)    # clustering algorithms
library(factoextra) # clustering visualization
library(dendextend) # for comparing two dendrograms
```


```{r}
dataClus <-read.delim("./BinaryNew.txt", header = TRUE)
```

Dissimilarity matrix
```{r}
HC <- dist(dataClus[2:13], method = "euclidean")
```

Hierarchical clustering using wards method
```{r}
hc1 <- hclust(HC, method = "ward.D2" )
```

Plot the obtained dendrogram with Labels
```{r}
plot(hc1, cex = 0.6, labels = dataClus$Code, hang = -1)
```
make subgroups
```{r}
plot(hc1, labels = dataClus$Code, cex = 0.6)
rect.hclust(hc1, k = 6, border = 2:5)
```

Based on the above data clusters were named as follows;

CLuster 1: Learning Aspects
Cluster 2  Disposition (Attitude towards study)
Cluster 3: Political Aspects
Cluster 4: Curriculum Aspects
Cluster 5: Institutional Support
Cluster 6: Social and behavioural


Identify dropout reasons ordered from the least referenced to the most referenced in participants input

```{r}
dataDR1 <-read.table("./Allfreq.txt", header = TRUE)
```


```{r}
dd <- dist(scale(dataDR1[2]), method = "euclidean")
hc1 <- hclust(dd, method = "ward.D2")
plot(hc1, labels = dataDR1$Code, cex = 0.6)
rect.hclust(hc1, k = 6, border = 2:5)
```



To idenitfy the most prominent dropout reasons based on the frequencies of dropout

```{r}
dataDR <-read.table("./FreqDR.txt", header = TRUE)
```



```{r}
ggplot(dataDR, aes(x=Code, y=Fre, fill=Fre)) +
geom_bar(stat="identity") +
coord_flip()
```

